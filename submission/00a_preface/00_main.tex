\prefacesection{Abstract}

Drone cameras are now being deployed in a wide range of applications, including Hollywood filmmaking, search and rescue, wildlife monitoring, and large-scale 3D scanning.
However, drones remain difficult to control, both for humans and for computers.
Drones are difficult for humans to control, because a human operator must either: express commands using counter-intuitive hand-held joysticks; or painstakingly specify waypoints using primitive mission planning software.
Drones are also difficult for computers to control, because an effective control algorithm must carefully reason about the non-linear dynamics and physical limits of the drone, obstacles in the drone's surroundings, and uncertainty in the drone's on-board sensor measurements.

In this dissertation, we introduce a variety of trajectory optimization methods that make it easier for people to use drone cameras.
We focus specifically on two different applications: drone cinematography and drone 3D scanning.
Throughout this dissertation, we will leverage domain knowledge that is specialized to each application, and we will reformulate classical trajectory optimization problems in terms of the drone camera's visual output, i.e., in terms of what the drone is \emph{seeing}.

We begin by introducing a software tool for designing and autonomously executing cinematography shots with quadrotor cameras.
Our tool enables users to: (1) specify shots visually using keyframes; (2) preview the resulting shots in a virtual environment; (3) precisely control the timing of shots using easing curves; and (4) capture the resulting shots in the real world with a single button click using a commercially available quadrotor camera.
To support our tool, we introduce a physical model for quadrotor cameras, and we derive an algorithm for generating camera trajectories that agree with our physical model.
We evaluate our tool in a user study with novice and expert cinematographers.
We show that our tool makes it possible for novices and experts to design compelling shots, and capture them fully autonomously.

To further support our shot planning tool, we introduce a fast and user-friendly algorithm for generating camera trajectories that respect the dynamics and physical limits of quadrotor hardware.
We demonstrate that our algorithm is between 25$\times$ and 180$\times$ faster than a general-purpose trajectory optimization approach implemented using a commercially available solver.
We successfully capture real video footage using the trajectories generated by our algorithm.
We show that the resulting videos are faithful to virtual shot previews, even when the trajectories being executed are at our quadrotor's physical limits.

Finally, we turn our attention from cinematography to 3D scanning.
We introduce an algorithm to generate drone camera trajectories, such that the imagery acquired during the flight will later produce a high-fidelity 3D model. Our method uses a coarse estimate of the scene geometry to plan camera trajectories that: (1) cover the scene as thoroughly as possible; (2) observe the scene geometry from a diverse set of viewing angles; (3) avoid obstacles; and (4) respect a user-specified flight time
budget. Our method relies on a mathematical model of scene coverage that exhibits an intuitive diminishing returns property known as \emph{submodularity}.
We leverage this property extensively to design a trajectory planning algorithm  that reasons globally about the non-additive coverage reward obtained across a trajectory, jointly with the cost of traveling between views.
We evaluate our method by using it to scan three large outdoor scenes, and we perform a quantitative evaluation using a photorealistic video game simulator.
