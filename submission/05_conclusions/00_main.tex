\textbf{ROUGH DRAFT (JUST THE SCRIPT FROM MY JOB TALK FOR NOW)}

~

\hspace{-15pt}So let’s zoom out. What did we actually do?
The whole point of this talk, is that we set out to make drone cameras more useful.
To get there, we used the language of trajectory optimization to express high-level user goals, and to solve for low-level drone actions.
And we used domain knowledge to design specialized algorithms, that were tailored to a particular camera task.
So we didn’t try to solve general drone intelligence, but we were SELECTIVE, and we tried to make a couple of TARGETED CREATIVE tasks, easier for users to specify.

But zooming out further, I think the EVEN BIGGER story here is that we don’t just want our robots to go from A to B.
From start position to goal position.
We want our robots to help us CREATE.

We saw this at the start of the talk, when we used drones to help us create ambitious cinematography that we wouldn’t have been able to get otherwise.
And of course there is a ton of exciting work that we still have to do in the cinematography space.
Using activity forecasting to do plan smarter shots in real-time, incorporating richer models of social saliency, filming with multiple drones, bullet-time effects, time-lapse photography.
The list goes on.

We also saw this idea of robot-enabled creativity support, when we used drones to CREATE high-quality 3D models of the environment.
And there is an absolute ton of exciting work to do in this space as well.
Working with cooperating teams of drones, scaling to very large scenes, moving indoors, and using active lighting to capturing richer materials.
The list goes on here too.

But this idea of robots helping us create is much bigger, because there are so many more creative tasks that we’d like help with.
One big idea that I’m super excited about using drones with lights on them to create swarming 3D displays.
But how should we specify the goals for the system?
And how do we COMPILE an animation into 10000 little drone trajectories without collisions, and subject to all the other appropriate constraints?

Another big idea that I’m excited about is getting our household chore robots to help us with creative tasks at home.
The big one for me is cooking.
But there are other creative tasks like assembling furniture, rearranging stuff, packing, unpacking, moving stuff in, moving stuff out.
But these planning problems are even hard for humans!
So how do we turn our high-level tasks into robot trajectories that we can actually execute?

And more broadly, I’m excited for robots to help us build, assemble, and on-demand infrastructure like roads and bridges.
But again, how do we convert our high-level goals into these VERY LONG-RANGE robot trajectories that will complete the tasks?
So, to summarize, we want our robots to help us CREATE. The resulting problems are HARD.
But the language of trajectory optimization gives us the tools we need.
And now is the time to try, because the next generation of consumer-facing robots is just around the corner.
